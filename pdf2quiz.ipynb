{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### poppler-utils 설치 (필요시)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Poppler 홈페이지](https://poppler.freedesktop.org/)를 통해 다운로드 혹은 아래 코드를 이용 <span style=\"opacity: 0.5;\">(아래 코드 이용시 윈도우의 경우 Chocolatey 설치 필요)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "def is_conda():\n",
    "    return \"conda\" in sys.prefix or os.path.exists(os.path.join(sys.prefix, \"conda-meta\"))\n",
    "\n",
    "os_name = platform.system()\n",
    "\n",
    "if is_conda():\n",
    "    os.system(\"conda install conda-forge::poppler -y\")\n",
    "elif os_name == \"Windows\":\n",
    "    os.system(\"choco install poppler-utils -y\")\n",
    "elif os_name == \"Linux\":\n",
    "    os.system(\"apt-get update && apt-get install -y poppler-utils\")\n",
    "elif os_name == \"Darwin\":\n",
    "    os.system(\"brew install poppler\")\n",
    "else:\n",
    "    print(\"지원되지 않는 OS이니 수동으로 poppler를 설치하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "from doclayout_yolo import YOLOv10\n",
    "from pdf2image import convert_from_path\n",
    "from konlpy.tag import Okt\n",
    "from keybert import KeyBERT\n",
    "import kss\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import Pix2StructForConditionalGeneration, AutoProcessor, AutoModelForSeq2SeqLM, AutoTokenizer, BertTokenizer, BertForNextSentencePrediction, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 레이아웃 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PDF -> jpg 꼴로 페이지 단위 이미지로 변환 (poppler 사용)\n",
    "2. YOLOv10 모델을 이용하여 영역 검출\n",
    "3. IOU를 계산하여 겹치는 부분 등의 문제 해결\n",
    "4. 각 구분마다 이미지를 크롭하고 메타데이터와 함께 이를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# PDF 파일을 페이지별 이미지(PIL Image)로 변환하는 함수\n",
    "def pdf_to_images(pdf_path, dpi=300):\n",
    "    images = convert_from_path(pdf_path, dpi=dpi)\n",
    "    print(f\"Converted PDF to {len(images)} page objects.\")\n",
    "    return images\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# YOLOv10 모델 로드 함수 (DocLayout-YOLO)\n",
    "def load_yolo_model():\n",
    "    filepath = hf_hub_download(\n",
    "        repo_id=\"juliozhao/DocLayout-YOLO-DocStructBench\",\n",
    "        filename=\"doclayout_yolo_docstructbench_imgsz1024.pt\"\n",
    "    )\n",
    "    return YOLOv10(filepath)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 두 박스 간 IoU 계산 함수\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    inter_x1 = max(x1, x3)\n",
    "    inter_y1 = max(y1, y3)\n",
    "    inter_x2 = min(x2, x4)\n",
    "    inter_y2 = min(y2, y4)\n",
    "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x4 - x3) * (y4 - y3)\n",
    "    return inter_area / (box1_area + box2_area - inter_area)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 중복 박스 제거 함수 (IoU 기준)\n",
    "def filter_duplicate_boxes(bounding_boxes, iou_threshold=0.5):\n",
    "    filtered_boxes = []\n",
    "    for box in bounding_boxes:\n",
    "        keep = True\n",
    "        for fbox in filtered_boxes:\n",
    "            iou = calculate_iou(\n",
    "                (box[\"x_min\"], box[\"y_min\"], box[\"x_max\"], box[\"y_max\"]),\n",
    "                (fbox[\"x_min\"], fbox[\"y_min\"], fbox[\"x_max\"], fbox[\"y_max\"])\n",
    "            )\n",
    "            if iou > iou_threshold:\n",
    "                if box[\"confidence\"] > fbox[\"confidence\"]:\n",
    "                    filtered_boxes.remove(fbox)\n",
    "                else:\n",
    "                    keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            filtered_boxes.append(box)\n",
    "    return filtered_boxes\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 고유 접미사 생성 (식별용)\n",
    "def generate_unique_suffix(index):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    return alphabet[index % len(alphabet)]\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 단일 이미지(페이지)에서 영역(박스) 검출 함수\n",
    "def process_image(image, model, page_number):\n",
    "    image_array = np.array(image)\n",
    "    det_res = model.predict(image_array, imgsz=1024, conf=0.2, device=DEVICE)\n",
    "    bounding_boxes = []\n",
    "    for i, box in enumerate(det_res[0].boxes):\n",
    "        class_name = model.names[int(box.cls)]\n",
    "        class_number = int(box.cls)\n",
    "        unique_suffix = generate_unique_suffix(i)\n",
    "        bounding_boxes.append({\n",
    "            \"class\": class_name,\n",
    "            \"confidence\": float(box.conf),\n",
    "            \"x_min\": float(box.xyxy[0][0]),\n",
    "            \"y_min\": float(box.xyxy[0][1]),\n",
    "            \"x_max\": float(box.xyxy[0][2]),\n",
    "            \"y_max\": float(box.xyxy[0][3]),\n",
    "            \"unique_id\": f\"page{page_number}_class{class_number}_{unique_suffix}\",\n",
    "            \"page_number\": page_number\n",
    "        })\n",
    "    filtered_boxes = filter_duplicate_boxes(bounding_boxes, iou_threshold=0.5)\n",
    "    return filtered_boxes\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# PDF 전체에 대해 페이지별 이미지 변환 및 영역 검출\n",
    "def process_pdf(pdf_path, model, dpi=300):\n",
    "    images = pdf_to_images(pdf_path, dpi=dpi)\n",
    "    all_detections = []\n",
    "    for page_number, image in enumerate(images, start=1):\n",
    "        detections = process_image(image, model, page_number)\n",
    "        all_detections.append(detections)\n",
    "    return images, all_detections\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 검출된 영역을 원본 이미지에서 크롭하고, bounding_box 및 page_number 정보를 포함해 분리\n",
    "def crop_detections(images, all_detections):\n",
    "    cropped_results = {\"table\": [], \"plain text\": [], \"figure\": []}\n",
    "    for detections in all_detections:\n",
    "        if not detections:\n",
    "            continue\n",
    "        page_number = detections[0][\"page_number\"]\n",
    "        image = np.array(images[page_number - 1])\n",
    "        for box in detections:\n",
    "            x_min = int(box[\"x_min\"])\n",
    "            y_min = int(box[\"y_min\"])\n",
    "            x_max = int(box[\"x_max\"])\n",
    "            y_max = int(box[\"y_max\"])\n",
    "            cropped_img = image[y_min:y_max, x_min:x_max]\n",
    "            category = box[\"class\"]\n",
    "            region_dict = {\n",
    "                \"unique_id\": box[\"unique_id\"],\n",
    "                \"image\": cropped_img,\n",
    "                \"page_number\": page_number,\n",
    "                \"bounding_box\": {\n",
    "                    \"x_min\": box[\"x_min\"],\n",
    "                    \"y_min\": box[\"y_min\"],\n",
    "                    \"x_max\": box[\"x_max\"],\n",
    "                    \"y_max\": box[\"y_max\"]\n",
    "                }\n",
    "            }\n",
    "            if category in cropped_results:\n",
    "                cropped_results[category].append(region_dict)\n",
    "            else:\n",
    "                if \"other\" not in cropped_results:\n",
    "                    cropped_results[\"other\"] = []\n",
    "                cropped_results[\"other\"].append(region_dict)\n",
    "    return cropped_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 평문 영역에서의 텍스트 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyOCR 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 평문 영역에서 EasyOCR으로 텍스트 추출 (EasyOCR 사용)\n",
    "class TextExtractorFromMemory:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reader = easyocr.Reader(['ko', 'en'], gpu=torch.cuda.is_available())\n",
    "        \n",
    "    def extract_text(self, image):\n",
    "        text_result = self.reader.readtext(image, detail=0)\n",
    "        text = \" \".join(text_result).strip()\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 평문 영역 처리 함수: 최종 출력 구조는 아래와 같이 함\n",
    "# {data_id, page_number, region_type, content, meta:{bounding_box: ...}}\n",
    "def process_plain_text_regions(plain_text_regions):\n",
    "    extractor = TextExtractorFromMemory()\n",
    "    results = []\n",
    "    for region in plain_text_regions:\n",
    "        unique_id = region[\"unique_id\"]\n",
    "        text = extractor.extract_text(region[\"image\"])\n",
    "        results.append({\n",
    "            \"data_id\": unique_id,\n",
    "            \"page_number\": region[\"page_number\"],\n",
    "            \"region_type\": \"평문\",\n",
    "            \"content\": text,\n",
    "            \"meta\": {\n",
    "                \"bounding_box\": region[\"bounding_box\"]\n",
    "            }\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 표 영역의 텍스트 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV와 EasyOCR을 기반으로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 표 영역 처리 함수: 표의 셀 텍스트 및 그리드 정보 추출\n",
    "def extract_text_from_cells(cells_data):\n",
    "    extracted_text = []\n",
    "    for cell in cells_data:\n",
    "        if 'text' in cell:\n",
    "            extracted_text.append(cell['text'])\n",
    "    return ' '.join(extracted_text)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 표 영역에서 표 구조 및 셀 텍스트 추출 (OpenCV와 EasyOCR 사용)\n",
    "class TableExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reader = easyocr.Reader(['ko', 'en'], gpu=torch.cuda.is_available())\n",
    "\n",
    "    def process_image(self, image):\n",
    "        if isinstance(image, str):\n",
    "            self.image = cv2.imread(image)\n",
    "        else:\n",
    "            self.image = image\n",
    "        self.result = self.image.copy()\n",
    "        self.detect_lines()\n",
    "        self.classify_lines_and_find_intersections()\n",
    "        self.remove_duplicate_points()\n",
    "        data, extracted_cells = self.extract_text_from_cells()\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        df = df.replace('', np.nan)\n",
    "        df = df.dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df.fillna('')\n",
    "        processed_cells = []\n",
    "        for i in range(len(df)):\n",
    "            for j in range(len(df.columns)):\n",
    "                original_cell = next((cell for cell in extracted_cells if cell['row'] == i + 1 and cell['col'] == j + 1), None)\n",
    "                if original_cell:\n",
    "                    processed_cells.append({\n",
    "                        'row': i + 1,\n",
    "                        'col': j + 1,\n",
    "                        'text': df.iloc[i, j],\n",
    "                        'coordinates': original_cell['coordinates']\n",
    "                    })\n",
    "        final_result = {'cells': processed_cells, 'grid_info': {'rows': len(df), 'cols': len(df.columns)}}\n",
    "        return final_result\n",
    "    \n",
    "    def detect_lines(self):\n",
    "        self.edges = cv2.Canny(self.image, 50, 150, apertureSize=3)\n",
    "        self.lines = cv2.HoughLinesP(self.edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "        return self.lines\n",
    "    \n",
    "    def classify_lines_and_find_intersections(self):\n",
    "        self.intersection_points = []\n",
    "        self.horizontal_lines = []\n",
    "        self.vertical_lines = []\n",
    "        if self.lines is not None:\n",
    "            for line in self.lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180.0 / np.pi)\n",
    "                if angle < 10 or angle > 170:\n",
    "                    self.horizontal_lines.append(line[0])\n",
    "                elif 80 < angle < 100:\n",
    "                    self.vertical_lines.append(line[0])\n",
    "            height, width = self.image.shape[:2]\n",
    "            margin = 10\n",
    "            self.horizontal_lines.append([margin, margin, width - margin, margin])\n",
    "            self.horizontal_lines.append([margin, height - margin, width - margin, height - margin])\n",
    "            self.vertical_lines.append([margin, margin, margin, height - margin])\n",
    "            self.vertical_lines.append([width - margin, margin, width - margin, height - margin])\n",
    "            self._find_intersection_points()\n",
    "            self._process_end_points()\n",
    "\n",
    "    def _find_intersection_points(self):\n",
    "        for h_line in self.horizontal_lines:\n",
    "            for v_line in self.vertical_lines:\n",
    "                x1, y1, x2, y2 = h_line\n",
    "                x3, y3, x4, y4 = v_line\n",
    "                denominator = ((x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4))\n",
    "                if denominator != 0:\n",
    "                    t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denominator\n",
    "                    u = -((x1 - x2) * (y1 - y3) - (y1 - y2) * (x1 - x3)) / denominator\n",
    "                    if 0 <= t <= 1 and 0 <= u <= 1:\n",
    "                        x = int(x1 + t * (x2 - x1))\n",
    "                        y = int(y1 + t * (y2 - y1))\n",
    "                        self.intersection_points.append((x, y))\n",
    "        self.intersection_points = sorted(set(self.intersection_points), key=lambda p: (p[1], p[0]))\n",
    "\n",
    "    def _process_end_points(self):\n",
    "        end_points = []\n",
    "        for line in self.horizontal_lines + self.vertical_lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            end_points.append((x1, y1))\n",
    "            end_points.append((x2, y2))\n",
    "        x_values = [point[0] for point in end_points]\n",
    "        y_values = [point[1] for point in end_points]\n",
    "        x_min, x_max = min(x_values), max(x_values)\n",
    "        y_min, y_max = min(y_values), max(y_values)\n",
    "        self.filtered_end_points = [(x, y) for (x, y) in end_points if (x_min <= x <= x_min + 10 or x_max - 10 <= x <= x_max) or (y_min <= y <= y_min + 10 or y_max - 10 <= y <= y_max)]\n",
    "        self.all_points = self.intersection_points + self.filtered_end_points\n",
    "\n",
    "    def remove_duplicate_points(self, distance_threshold=15):\n",
    "        self.unique_points = []\n",
    "        for point in self.all_points:\n",
    "            is_unique = True\n",
    "            for unique_point in self.unique_points:\n",
    "                distance = np.linalg.norm(np.array(point) - np.array(unique_point))\n",
    "                if distance <= distance_threshold:\n",
    "                    is_unique = False\n",
    "                    break\n",
    "            if is_unique:\n",
    "                self.unique_points.append(point)\n",
    "\n",
    "    def extract_text_from_cells(self, min_height=30, min_width=30):\n",
    "        self.x_coords = sorted(list(set([point[0] for point in self.intersection_points])))\n",
    "        self.y_coords = sorted(list(set([point[1] for point in self.intersection_points])))\n",
    "        data = []\n",
    "        extracted_cells = []\n",
    "        for i in range(len(self.y_coords) - 1):\n",
    "            row = []\n",
    "            for j in range(len(self.x_coords) - 1):\n",
    "                top_left_x = self.x_coords[j]\n",
    "                top_left_y = self.y_coords[i]\n",
    "                bottom_right_x = self.x_coords[j + 1]\n",
    "                bottom_right_y = self.y_coords[i + 1]\n",
    "                tile = self.image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "                cell_info = {'row': i + 1, 'col': j + 1, 'coordinates': {'top_left': (top_left_x, top_left_y), 'bottom_right': (bottom_right_x, bottom_right_y)}}\n",
    "                if tile.shape[0] < min_height or tile.shape[1] < min_width:\n",
    "                    row.append(\"\")\n",
    "                    cell_info['text'] = \"\"\n",
    "                    extracted_cells.append(cell_info)\n",
    "                    continue\n",
    "                text_result = self.reader.readtext(tile, detail=0)\n",
    "                text = \"\\n\".join(text_result).strip()\n",
    "                row.append(text)\n",
    "                cell_info['text'] = text\n",
    "                extracted_cells.append(cell_info)\n",
    "            data.append(row)\n",
    "        return data, extracted_cells\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 표 영역 처리 함수: 최종 출력 구조에 data_id, page_number, region_type, content, meta 포함\n",
    "def process_table_regions(table_regions):\n",
    "    table_extractor = TableExtractor()\n",
    "    results = []\n",
    "    for region in table_regions:\n",
    "        unique_id = region[\"unique_id\"]\n",
    "        try:\n",
    "            table_result = table_extractor.process_image(region[\"image\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Table extraction failed for {unique_id}: {e}\")\n",
    "            continue\n",
    "        table_text = extract_text_from_cells(table_result[\"cells\"])\n",
    "        results.append({\n",
    "            \"data_id\": unique_id,\n",
    "            \"page_number\": region[\"page_number\"],\n",
    "            \"region_type\": \"일반표\",\n",
    "            \"content\": table_text,\n",
    "            \"meta\": {\n",
    "                \"bounding_box\": region[\"bounding_box\"],\n",
    "                \"cells\": table_result.get(\"cells\", []),\n",
    "                \"grid\": table_result.get(\"grid_info\", {})\n",
    "            }\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 도표 영역 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pix2Struct를 기반하여 이를 사전 학습시킨 brainventures/deplot_kr을 불러와서 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 도표 영역 처리: Pix2Struct를 사용하여 도표 설명 생성\n",
    "class FigureExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.processor = AutoProcessor.from_pretrained(\"brainventures/deplot_kr\")\n",
    "        self.model = Pix2StructForConditionalGeneration.from_pretrained(\"brainventures/deplot_kr\")\n",
    "        self.model.to(DEVICE)\n",
    "        \n",
    "    def extract_figure_info(self, image):\n",
    "        if not isinstance(image, Image.Image):\n",
    "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = self.model.generate(**inputs, max_length=1024)\n",
    "        result = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        return result\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 도표 영역 처리 함수: 최종 출력 구조에 data_id, page_number, region_type, content, meta 포함\n",
    "def process_figure_regions(figure_regions):\n",
    "    figure_extractor = FigureExtractor()\n",
    "    results = []\n",
    "    for region in figure_regions:\n",
    "        unique_id = region[\"unique_id\"]\n",
    "        try:\n",
    "            figure_text = figure_extractor.extract_figure_info(region[\"image\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Figure extraction failed for {unique_id}: {e}\")\n",
    "            continue\n",
    "        results.append({\n",
    "            \"data_id\": unique_id,\n",
    "            \"page_number\": region[\"page_number\"],\n",
    "            \"region_type\": \"도표\",\n",
    "            \"content\": figure_text,\n",
    "            \"meta\": {\n",
    "                \"bounding_box\": region[\"bounding_box\"]\n",
    "            }\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# pdf를 json으로 변환하는 함수\n",
    "def pdf2json():\n",
    "    # 1. PDF 선택\n",
    "    pdf_folder = \"./\"\n",
    "    pdf_files = glob.glob(os.path.join(pdf_folder, \"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        print(\"PDF 파일을 찾을 수 없습니다.\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"\\n찾은 PDF 목록:\")\n",
    "        for i, pdf in enumerate(pdf_files, start=1):\n",
    "            print(f\"\\t{i}. {os.path.basename(pdf)}\")\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"\\n사용할 PDF 번호를 입력하세요: \"))\n",
    "                if 1 <= choice <= len(pdf_files):\n",
    "                    pdf_path = pdf_files[choice - 1]\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"유효한 번호를 입력하세요.\")\n",
    "            except ValueError:\n",
    "                print(\"숫자만 입력하세요.\")\n",
    "    # 2. 모델 로드, PDF→이미지 변환 및 영역 검출\n",
    "    model = load_yolo_model()\n",
    "    images, all_detections = process_pdf(pdf_path, model, dpi=300)\n",
    "    cropped_results = crop_detections(images, all_detections)\n",
    "    # 3. 영역별(평문, 표, 도표)로 분리\n",
    "    plain_text_regions = cropped_results.get(\"plain text\", [])\n",
    "    table_regions = cropped_results.get(\"table\", [])\n",
    "    figure_regions = cropped_results.get(\"figure\", [])\n",
    "    print(f\"Total plain text regions: {len(plain_text_regions)}\")\n",
    "    print(f\"Total table regions: {len(table_regions)}\")\n",
    "    print(f\"Total figure regions: {len(figure_regions)}\")\n",
    "    # 4. 각 영역별 텍스트 추출 및 처리\n",
    "    plain_text_extraction_results = process_plain_text_regions(plain_text_regions)\n",
    "    table_extraction_results = process_table_regions(table_regions)\n",
    "    figure_extraction_results = process_figure_regions(figure_regions)\n",
    "    # 5. 세 영역 결과를 합침\n",
    "    combined_results = plain_text_extraction_results + table_extraction_results + figure_extraction_results\n",
    "    # 6. 사람이 읽는 순서대로 정렬 (bounding_box의 y_min, x_min 순)\n",
    "    combined_results = sorted(combined_results, key=lambda x: (x[\"page_number\"], x[\"meta\"][\"bounding_box\"][\"y_min\"], x[\"meta\"][\"bounding_box\"][\"x_min\"]))\n",
    "    # 7. 최종 결과를 JSON 파일로 저장\n",
    "    RESULTS_DIR = \"PDF2JSON\"\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    final_combined_json = os.path.join(RESULTS_DIR, \"result.json\")\n",
    "    with open(final_combined_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(combined_results, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Combined JSON extraction results saved to: {final_combined_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 불용어 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 불용어 리스트 불러오기\n",
    "with open(\"stopwords-ko.txt\", 'r', encoding='utf-8') as f:\n",
    "    stop_words = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 텍스트 전처리 클래스\n",
    "class nlp_before_qg:\n",
    "    \n",
    "    def __init__(self, cv_df):\n",
    "        page_num = str(input(\"원하는 페이지 번호 입력(ex: 5 혹은 1-4 혹은 all): \")) # 원하는 페이지 번호 입력 (예: 5, 1-4, all)\n",
    "        self.cv_df = cv_df\n",
    "        self.page_num = page_num\n",
    "        self.raw_text = None\n",
    "        self.text = None\n",
    "        self.text_list = None\n",
    "        self.text_summary = None\n",
    "        self.con_split = None\n",
    "        self.key_word = None\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 원본 텍스트 추출 함수: 지정된 페이지 번호에 해당하는 텍스트 추출\n",
    "    def raw_text_extract(self):\n",
    "        df = self.cv_df.copy()\n",
    "        page_num = self.page_num\n",
    "        if page_num == 'all':\n",
    "            df = df.loc[df['region_type'] == '평문', ['page_number', 'region_type', 'content']] # 모든 페이지에서 '평문' 영역 텍스트 추출\n",
    "            df.loc[:, 'content'] = df['content'].str.replace(':', '.')\n",
    "            raw_text = df['content'].to_list()\n",
    "        else:\n",
    "            start, end = (map(int, page_num.split('-')) if \"-\" in page_num else (int(page_num), int(page_num))) # 특정 페이지 범위에서 '평문' 영역 텍스트 추출\n",
    "            end += 1\n",
    "            page_list = range(start, end, 1)\n",
    "            df = df.loc[df['region_type'] == '평문', ['page_number', 'region_type', 'content']]\n",
    "            df['content'] = df['content'].str.replace('다:', '다.')\n",
    "            raw_text = df.loc[df['page_number'].isin(page_list), 'content'].to_list()\n",
    "        self.raw_text = raw_text\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 불필요한 문자 및 개행 문자 제거 함수\n",
    "    def text_resub(self):\n",
    "        text_list = self.raw_text\n",
    "        text = []\n",
    "        for sent in tqdm(text_list, desc=\"불필요한 부분 제거\", unit=\"sentences\"):\n",
    "            sent = re.sub('[^a-zA-Zㄱ-ㅣ가-힣0-9.\\s()]', '', sent)\n",
    "            sent = re.sub('[\\n]', '', sent)\n",
    "            text.append(sent)\n",
    "        self.text = \" \".join(text)\n",
    "        print(\"불필요한 부분 제거 완료\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 문장 분리 함수: KSS 라이브러리를 사용하여 문장 단위로 분리\n",
    "    def split_sentence(self):\n",
    "        self.text_list = kss.split_sentences(self.text)\n",
    "        print(\"문장 분리 완료\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 텍스트 요약 함수: KoT5 모델을 사용하여 요약 수행\n",
    "    def summary_sentence(self):\n",
    "        text = self.text_list\n",
    "        device_t = 0 if DEVICE == \"cuda\" else -1\n",
    "        model_name = \"psyche/KoT5-summarization\"\n",
    "        summarizer = pipeline(\"summarization\", model=model_name, device=device_t)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        summary_list = []\n",
    "        for t in tqdm(text, desc=\"요약 실행\", unit=\"sentences\"):\n",
    "            tokens = tokenizer.encode(t, return_tensors=\"pt\")\n",
    "            max_length = int(len(tokens[0]))\n",
    "            min_length = 30 if max_length >= 30 else max_length\n",
    "            summary = summarizer(t, min_length=min_length, max_length=max_length, do_sample=False)[0][\"summary_text\"]\n",
    "            summary_list.append(summary)\n",
    "        self.text_summary = summary_list\n",
    "        print(\"요약 완료\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 문맥 구분 함수: BERT NSP 모델을 사용하여 문맥 자동 분할\n",
    "    def context_split(self):\n",
    "        sentences = self.text_summary\n",
    "        model_path = '0Kyung/KoBERT-NextSentencePrediction' # NSP 모델 로드\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        model = BertForNextSentencePrediction.from_pretrained(model_path).to(DEVICE).eval()\n",
    "        transition_adverbs = [\"그러나\", \"하지만\", \"반면\", \"반대로\", \"달리\", \"불구하고\", \"그럼에도\"] # 연결 부사를 이용한 가중치 조정\n",
    "\n",
    "        def get_nsp_score(sent1, sent2):\n",
    "            tokens = tokenizer(sent1, sent2, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "            tokens = {key: value.to(DEVICE) for key, value in tokens.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**tokens)\n",
    "            logits = outputs.logits\n",
    "            return torch.softmax(logits, dim=1)[:, 0].item()\n",
    "\n",
    "        def calculate_weighted_similarity(sent1, sent2):\n",
    "            score = get_nsp_score(sent1, sent2)\n",
    "            return score + (0.1 if any(adverb in sent2 for adverb in transition_adverbs) else 0)\n",
    "\n",
    "        nsp_scores = [calculate_weighted_similarity(sentences[i], sentences[i+1]) for i in range(len(sentences)-1)]\n",
    "        Q1, Q3 = np.quantile(nsp_scores, [0.25, 0.75]) # 이상치 탐지를 통한 문맥 분할\n",
    "        threshold = Q3 + 1.5 * (Q3 - Q1)\n",
    "        change_points = [i for i, score in enumerate(nsp_scores) if score > threshold]\n",
    "        con_split, start = [], 0\n",
    "        for change in change_points:\n",
    "            con_split.append(\" \".join(sentences[start:change+1]))\n",
    "            start = change + 1\n",
    "        con_split.append(\" \".join(sentences[start:]))\n",
    "        self.con_split = con_split\n",
    "        print(\"문맥 구분 완료\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 키워드 추출 함수: KeyBERT를 사용하여 각 문맥별 핵심 키워드 추출\n",
    "    def keybert(self):\n",
    "        con_split = self.con_split\n",
    "    \n",
    "        def mmr(doc_embedding, candidate_embeddings, words, top_n=5, diversity=0.5):\n",
    "            word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "            word_similarity = cosine_similarity(candidate_embeddings)\n",
    "            keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "            candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "            for _ in range(top_n - 1):\n",
    "                if not candidates_idx:  # 후보가 없다면\n",
    "                    print(\"No more candidates left!\")\n",
    "                    break\n",
    "                candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "                target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "                mmr = (1 - diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "                if mmr.size == 0:  # mmr이 비어 있다면\n",
    "                    print(\"MMR array is empty!\")\n",
    "                    break\n",
    "                mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "                keywords_idx.append(mmr_idx)\n",
    "                candidates_idx.remove(mmr_idx)\n",
    "            return [words[idx] for idx in keywords_idx]\n",
    "\n",
    "        embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', device = DEVICE)\n",
    "        kw_model = KeyBERT(embedding_model)\n",
    "        final = []\n",
    "        for text in tqdm(con_split, desc=\"키워드 추출\", unit=\"contexts\"):\n",
    "            if not text.strip():\n",
    "                final.append([])\n",
    "                continue\n",
    "            keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), use_maxsum=False, top_n=10)\n",
    "            candidate = [key[0] for key in keywords]\n",
    "            doc_embedding = embedding_model.encode([text])\n",
    "            candidate_embedding = embedding_model.encode(candidate)\n",
    "            key_result = mmr(doc_embedding, candidate_embedding, candidate, top_n=3, diversity=0.5)\n",
    "            final.append(key_result)\n",
    "        okt = Okt()\n",
    "        key_total = []\n",
    "        for word_list in tqdm(final, desc=\"불용어 처리\", unit=\"keywords\"):\n",
    "            if not word_list:\n",
    "                continue\n",
    "            key_final = []\n",
    "            for word in word_list:\n",
    "                nouns = okt.nouns(word)\n",
    "                for i in range(len(nouns)):\n",
    "                    if nouns[i] in stop_words:\n",
    "                        nouns[i] = ''\n",
    "                joined = \"\".join(nouns)\n",
    "                key_final.append(joined)\n",
    "            key_total.append(key_final)\n",
    "\n",
    "        self.key_word = key_total\n",
    "        print(\"키워드 추출 완료\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 최종 결과를 데이터프레임으로 변환\n",
    "    def merge_to_df(self):\n",
    "        return pd.DataFrame(zip(self.con_split, self.key_word), columns=['context', 'keyword'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON to context & keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# JSON 파일을 불러와 NLP 처리 후 저장하는 함수\n",
    "def json_processing():\n",
    "    # 1. JSON 선택\n",
    "    json_folder = \"./PDF2JSON\"\n",
    "    json_files = glob.glob(os.path.join(json_folder, \"*.json\"))\n",
    "    if not json_files:\n",
    "        print(\"JSON 파일을 찾을 수 없습니다.\")\n",
    "        return\n",
    "    print(\"\\n찾은 JSON 파일 목록:\")\n",
    "    for idx, file in enumerate(json_files, start=1):\n",
    "        print(f\"\\t{idx}. {os.path.basename(file)}\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"\\n사용할 JSON 번호를 입력하세요: \"))\n",
    "            if 1 <= choice <= len(json_files):\n",
    "                json_path = json_files[choice - 1]\n",
    "                break\n",
    "            else:\n",
    "                print(\"유효한 번호를 입력하세요.\")\n",
    "        except ValueError:\n",
    "            print(\"숫자만 입력하세요.\")\n",
    "    # 2. json 파일 로드\n",
    "    input_df = pd.read_json(json_path)\n",
    "    # 3. Processor 클래스를 사용하여 NLP 처리 수행\n",
    "    nbq = nlp_before_qg(input_df)\n",
    "    nbq.raw_text_extract()\n",
    "    nbq.text_resub()\n",
    "    nbq.split_sentence()\n",
    "    nbq.summary_sentence()\n",
    "    nbq.context_split()\n",
    "    nbq.keybert()\n",
    "    new_df = nbq.merge_to_df()\n",
    "    # 4. 저장\n",
    "    final_path = os.path.join('JSON2JSON', 'result.json')\n",
    "    directory = os.path.dirname(final_path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \"\"\"if os.path.exists(final_path):\n",
    "        user_input = input(f\"File {final_path} already exists. Overwrite? (y/n): \").lower()\n",
    "        if user_input != 'y':\n",
    "            print(f\"Skipping {final_path}\")\n",
    "            return\"\"\"\n",
    "    new_df.to_json(final_path, orient='records', force_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# ox 문제 생성 함수\n",
    "def generate_ox(model, tokenizer, context, ox):\n",
    "    ox_str = \"True\" if ox else \"False\"\n",
    "    input_text = f\"context: {context}\\n ox: {ox_str}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "    with torch.no_grad(): output_ids = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=25, do_sample=True, top_k=50, top_p=0.9, repetition_penalty=3.0, no_repeat_ngram_size=2, num_beams=10, early_stopping=True)\n",
    "    question = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    question = re.sub(r'다(\\.다)+\\.', '다.', question)\n",
    "    question = re.sub(r'\\.\\.+', '.', question)\n",
    "    question = re.sub(r'(?<=다\\.)(?=[^\\s])', ' ', question)\n",
    "    question = question.strip()\n",
    "    last_period_index = question.rfind('.')\n",
    "    if last_period_index:\n",
    "        question = question[:last_period_index+1]\n",
    "    return question\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 주관식 문제 생성 함수\n",
    "def generate_short(model, tokenizer, context, answer):\n",
    "    input_text = f\"질문 생성: {answer} 문맥: {context}\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.DEVICE)\n",
    "    with torch.no_grad(): outputs = model.generate(input_ids, max_length=40, num_beams=3, repetition_penalty=1.5, no_repeat_ngram_size=2, temperature=1.0, top_k=30, top_p=0.8, early_stopping=True)\n",
    "    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    question = re.sub(r\"\\?.*\", \"?\", question).strip()\n",
    "    return question\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 빈칸 문제 생성 함수\n",
    "def generate_blank(context, keyword):\n",
    "    return context.replace(keyword, \"[\"+len(keyword)*\" \"+\"]\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 서술형 문제 생성 함수\n",
    "def generate_essay(keyword):\n",
    "\t\treturn keyword + \"에 대해 서술하시오.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 주관식 문제 모델 로드\n",
    "shrot_tokenizer = AutoTokenizer.from_pretrained(\"PG18/Generate_shortanswer_question\")\n",
    "shrot_model = AutoModelForSeq2SeqLM.from_pretrained(\"PG18/Generate_shortanswer_question\").to(DEVICE)\n",
    "shrot_model.eval()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# ox 문제 모델 로드\n",
    "ox_tokenizer = AutoTokenizer.from_pretrained(\"asteroidddd/kobart-oxquiz\")\n",
    "ox_model = AutoModelForSeq2SeqLM.from_pretrained(\"asteroidddd/kobart-oxquiz\").to(DEVICE)\n",
    "ox_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "찾은 PDF 목록:\n",
      "\t1. 강의자료.pdf\n",
      "Converted PDF to 12 page objects.\n",
      "\n",
      "0: 576x1024 1 figure, 60.0ms\n",
      "Speed: 4.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 2 titles, 5 plain texts, 58.0ms\n",
      "Speed: 4.0ms preprocess, 58.0ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 3 plain texts, 71.0ms\n",
      "Speed: 4.0ms preprocess, 71.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 5 plain texts, 63.0ms\n",
      "Speed: 4.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 1 plain text, 64.0ms\n",
      "Speed: 4.0ms preprocess, 64.0ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 6 plain texts, 63.0ms\n",
      "Speed: 4.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 figure, 1 figure_caption, 58.0ms\n",
      "Speed: 4.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 7 plain texts, 61.0ms\n",
      "Speed: 4.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 6 plain texts, 56.0ms\n",
      "Speed: 4.0ms preprocess, 56.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 5 plain texts, 60.0ms\n",
      "Speed: 4.0ms preprocess, 60.0ms inference, 3.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 1 plain text, 60.0ms\n",
      "Speed: 5.0ms preprocess, 60.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "\n",
      "0: 576x1024 1 title, 1 plain text, 1 table, 1 table_caption, 72.0ms\n",
      "Speed: 4.0ms preprocess, 72.0ms inference, 4.0ms postprocess per image at shape (1, 3, 576, 1024)\n",
      "Total plain text regions: 33\n",
      "Total table regions: 1\n",
      "Total figure regions: 2\n",
      "Combined JSON extraction results saved to: PDF2JSON\\result.json\n",
      "\n",
      "찾은 JSON 파일 목록:\n",
      "\t1. result.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "불필요한 부분 제거: 100%|██████████| 33/33 [00:00<?, ?sentences/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불필요한 부분 제거 완료\n",
      "문장 분리 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "요약 실행: 100%|██████████| 34/34 [00:15<00:00,  2.26sentences/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 완료\n",
      "문맥 구분 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "키워드 추출: 100%|██████████| 4/4 [00:00<00:00, 14.13contexts/s]\n",
      "불용어 처리: 100%|██████████| 4/4 [00:00<00:00, 222.17keywords/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드 추출 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdf2json()\n",
    "json_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bitamin_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
